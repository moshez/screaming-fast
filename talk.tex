\usepackage{hyperref}
\usepackage{graphicx}
\usepackage{listings}
\usepackage{textcomp}
\usepackage{fancyvrb}

\title{Screaming Fast API Clients}
\author{Moshe Zadka -- https://cobordism.com}
\date{2020}

\begin{document}
\begin{titlepage}
\maketitle
\end{titlepage}

\frame{\titlepage}

I live in the San Francisco Bay Area.
I want to acknowledge that the San Francisco Bay Area
is the ancestral home of the Muweka Ohlone.

\begin{frame}
\frametitle{Acknowledgement of Country}

San Francisco Bay Area

Ancestral home of the Muweka Ohlone.

\end{frame}

\begin{frame}
\frametitle{Latency is the Site Killer}

Every 100ms of latency in your site lose more customers

\end{frame}

\begin{frame}
\frametitle{(Micro)service Architecture}

Layers

\end{frame}

\begin{frame}
\frametitle{(Micro)service Architecture}

Fan-out

\end{frame}

\begin{frame}
\frametitle{Lognormal Black Swans}

\begin{itemize}
\item Lognormal: $~1/x$ (kinda)
\item Normal: $~e^{-x^2}$
\end{itemize}

\end{frame}

You are extremely unlikely to meet someone over seven feet,
even if you are invited to an NBA team after party --
but some of my posts are 4000 words long,
about 5 standard deviations from my average of 500 words:
this is like meeting someone who's 7 feet two inches
in your local grocery store!

\begin{frame}
\frametitle{Averages Lie}

Only good for normal distributions

\end{frame}

\begin{frame}
\frametitle{Your Backend is Slow}

Lognormal, not normal

\end{frame}

\begin{frame}
\frametitle{Multiplicity Magnifies Outliers}

With 5 queries:

\begin{itemize}
\item P90 becomes P50
\item P99 becomes P90
\end{itemize}

\end{frame}

\begin{frame}
\frametitle{Let's Write Some Code}

\lstinputlisting[firstline=14]{middle-fanout.py}

\end{frame}

This is simplified code that shows what usually goes on
in the "middle tier":
makes some queries to the backend,
do some local computation,
and return a JSON.

How long does it take?
The sum of all the times.
This means that a backend that is *occasionally* slow
will make this function *almost always* slow.

\begin{frame}
\frametitle{Let's Write Some Code}

\lstinputlisting[firstline=15,lastline=22]{middle-fanout-klein.py}

\end{frame}

Parallelizing clients means taking a maximum,
not the sum.
What's the difference?
If you are almost sure to get a single slow hit,
now the timing is constant:
it does not matter if it is 2 or 1.

Being slowest as the slowest request,
and not the sum of the two slowest requests,
is progress.

\begin{frame}
\frametitle{Let's Simulate}

With fanout of 10:

\begin{itemize}
\item P50: each: 0.04 seq: 0.82 par 0.3
\item P90: each: 0.23 seq: 1.8 par 0.98
\item P99: each: 1.04 seq: 4.33 par 3.05
\end{itemize}

\end{frame}

While it does not improve the P99 by much,
parallelization gives us 3x-2x speedups
at P50 and P99.

\begin{frame}
\frametitle{Timing Out and Retry}

Temporary slow-downs

\end{frame}

When backends are slow, this is often transient.
A single host might be overloaded.
The disk might be busy.
A packet might be lost.
Giving up quickly and retrying can often mean the difference.

\begin{frame}
\frametitle{Let's Write Some Code}

\lstinputlisting[firstline=15,lastline=21]{middle-fanout-klein-retry.py}

\end{frame}


\begin{frame}
\frametitle{Let's Simulate}

\begin{itemize}
\item P50: 0.1 (~x8 naive, x3 parallel)
\item P90: 0.44
\item P99: 1.2 (~x4 naive, x3 parallel) \pause
\end{itemize}

\end{frame}

\begin{frame}
\frametitle{Let's Simulate}

Retried requests: 25%

\end{frame}


\begin{frame}
\frametitle{Let's Write Some Code}

\lstinputlisting[firstline=15,lastline=21]{middle-fanout-klein-retry-fail.py}

\end{frame}

\begin{frame}
\frametitle{Let's Simulate}

TBD

\end{frame}

\begin{frame}
\frametitle{Summary}
\end{frame}

\end{document}
